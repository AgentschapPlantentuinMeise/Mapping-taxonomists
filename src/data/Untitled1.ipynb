{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83082319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6aaad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melanie\\AppData\\Local\\Temp\\ipykernel_12256\\2542485849.py:12: DtypeWarning: Columns (9,10,16,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  backbone = pd.read_csv(\"../../data/external/backbone/Taxon.tsv\", sep=\"\\t\", on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "authors = pd.read_pickle(\"../../data/interim/european_taxonomic_authors_no_duplicates.pkl\")\n",
    "# less columns and author ID as index quicken processing\n",
    "authors = authors[[\"author_id\", \"author_display_name\", \"orcid\",\n",
    "                   \"inst_id\", \"inst_display_name\",  \"species_subject\"]]\n",
    "authors = authors.set_index(\"author_id\")\n",
    "\n",
    "levels = [\"genus\", \"family\", \"order\", \"class\", \"phylum\", \"kingdom\"]\n",
    "for level in levels:\n",
    "    authors[level] = [list() for x in range(len(authors.index))]\n",
    "\n",
    "# GBIF taxonomic backbone\n",
    "backbone = pd.read_csv(\"../../data/external/backbone/Taxon.tsv\", sep=\"\\t\", on_bad_lines='skip')\n",
    "\n",
    "# reduce size of backbone for easier searching\n",
    "backbone = backbone[backbone[\"taxonomicStatus\"]!=\"doubtful\"]\n",
    "backbone = backbone[[\"canonicalName\",] + levels]\n",
    "# remove taxa with no known species name, genus, family,...\n",
    "backbone = backbone.dropna().drop_duplicates(ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d89bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial first name + last name for every author\n",
    "truncated_names = []\n",
    "\n",
    "for author in authors.itertuples():\n",
    "    first_initial = author.author_display_name[0]\n",
    "    last_name = author.author_display_name.split(\" \")[-1]\n",
    "    truncated_names.append(first_initial + \" \" + last_name)\n",
    "    \n",
    "authors[\"truncatedName\"] = truncated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015d8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone to dictionary for quicker processing\n",
    "seen_species = {}\n",
    "\n",
    "for species in backbone.itertuples():\n",
    "    if species.canonicalName not in seen_species:\n",
    "        seen_species[species.canonicalName] = list(species)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec81bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every author, break down each species associated with them into genus, family,... etc\n",
    "for i, author in authors.iterrows():\n",
    "    for species in author[\"species_subject\"]:\n",
    "        if species in seen_species:\n",
    "            # taxonomic levels such as genus, family\n",
    "            for l, level in enumerate(levels):\n",
    "                taxon_name = seen_species[species][l]\n",
    "                # make sure there are no duplicates\n",
    "                if taxon_name not in author[level]:\n",
    "                    authors.loc[i, level].append(taxon_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d333ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(a, b):\n",
    "    same = False\n",
    "    # if no known orders for one of them, just use institution \n",
    "    if a.order == [] or b.order == []:\n",
    "        if a.inst_id == b.inst_id:\n",
    "            same = True\n",
    "    # if both have known orders, orders and institution must match\n",
    "    else:\n",
    "        if a.inst_id == b.inst_id and len(set(a.order).intersection(set(b.order))) > 0:\n",
    "            same = True\n",
    "    \n",
    "    return same\n",
    "\n",
    "\n",
    "def cluster(matches):\n",
    "    clusters = []\n",
    "    \n",
    "    for match in matches:\n",
    "        # first list\n",
    "        if len(clusters) == 0:\n",
    "            clusters.append(match)\n",
    "        # check if it matches any existing groups\n",
    "        match_with_groups = []\n",
    "        for i, group in enumerate(clusters):\n",
    "            if len(set(match).intersection(set(group))) > 0:\n",
    "                match_with_groups.append(i)\n",
    "        print(match_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c223fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(a, b):\n",
    "    same = False\n",
    "    # if no known orders for one of them, just use institution \n",
    "    if a.order == [] or b.order == []:\n",
    "        if a.inst_id == b.inst_id:\n",
    "            same = True\n",
    "    # if both have known orders, orders and institution must match\n",
    "    else:\n",
    "        if a.inst_id == b.inst_id and len(set(a.order).intersection(set(b.order))) > 0:\n",
    "            same = True\n",
    "    \n",
    "    return same\n",
    "\n",
    "\n",
    "def cluster(matches):\n",
    "    clusters = []\n",
    "    \n",
    "    for match in matches:\n",
    "        # check if it matches any existing groups\n",
    "        match_with_groups = []\n",
    "        for i, group in enumerate(clusters):\n",
    "            if len(set(match).intersection(set(group))) > 0:\n",
    "                match_with_groups.append(i)\n",
    "        \n",
    "        # if it fits with no existing group, add it by itself\n",
    "        if len(match_with_groups) == 0:\n",
    "            clusters.append(match)\n",
    "        # if it fits with one existing group, add it to that group\n",
    "        elif len(match_with_groups) == 1:\n",
    "            clusters[match_with_groups[0]].extend(match)\n",
    "        # if it fits with multiple groups, mash those groups together\n",
    "        else:\n",
    "            print(clusters) # apparently this never happens\n",
    "            supergroup = []\n",
    "            # remove each group and add its contents to the new supergroup\n",
    "            for j in match_with_groups.sort(reverse=True):\n",
    "                supergroup.extend(clusters.pop(j))\n",
    "            supergroup.extend(match)\n",
    "            clusters.append(supergroup)\n",
    "            print(clusters)\n",
    "    \n",
    "    # turn into a list of sets to get unique values\n",
    "    clusters = [set(x) for x in clusters] \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b275d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emergency meeting: go over every duplicated name\n",
    "true_people = []\n",
    "duplicates = authors[authors.duplicated(subset=[\"truncatedName\"], keep=False)]\n",
    "\n",
    "for name in set(duplicates[\"truncatedName\"]):\n",
    "    # get all trund names that are exact string matches to this name\n",
    "    #same_names = duplicates[duplicates[\"author_display_name\"]==name]\n",
    "    same_names = duplicates[duplicates[\"truncatedName\"]==name]\n",
    "    matches = []\n",
    "    \n",
    "    for person_a in same_names.itertuples():\n",
    "        aliases = [person_a.Index,]\n",
    "        \n",
    "        for person_b in same_names.itertuples():\n",
    "            if match(person_a, person_b) and person_a.Index!=person_b.Index:\n",
    "                aliases.append(person_b.Index)\n",
    "                \n",
    "        matches.append(aliases)\n",
    "\n",
    "    true_people.extend(cluster(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a05198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melanie\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:576: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.concat(merged_people, ignore_index=True)        \n",
    "merged_df.to_csv(\"../../data/interim/merged_people.csv\")\n",
    "\n",
    "true_authors.to_pickle(\"../../data/processed/european_authors_disambiguated.pkl\")\n",
    "true_authors.to_csv(\"../../data/processed/european_authors_disambiguated.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
